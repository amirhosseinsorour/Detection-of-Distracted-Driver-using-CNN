{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "import cv2\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from numpy.random import permutation\n",
    "np.random.seed(2016)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, MaxPool2D # GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras import utils\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "from keras import regularizers\n",
    "import h5py\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Convolution2D, \\\n",
    "    GlobalAveragePooling2D, Dense, BatchNormalization, Activation, Conv2D\n",
    "from keras.models import Model\n",
    "# from keras.engine.topology import get_source_inputs\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.utils import get_source_inputs, plot_model\n",
    "# from depthwise_conv2d import DepthwiseConvolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cache = 1\n",
    "dataset_path = r'../Project/Dataset/'\n",
    "np.random.seed(2016)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(src=img, dsize=(224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    df = pd.read_csv(dataset_path + 'auc.distracted.driver.train.csv')\n",
    "    x = df.iloc[:,0]\n",
    "    y = df.iloc[:,1]\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    print('Read train images')\n",
    "    for i in range (0,len(x)):\n",
    "        fl= dataset_path + r'v1_cam1_no_split/' + r'/'.join(x[i].split('/')[-2:])\n",
    "        print(f\"Reading image {i}/{len(x)}\")\n",
    "        img = get_im_cv2(fl)\n",
    "        X_train.append(img)\n",
    "        Y_train.append(y[i])\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_valid():\n",
    "    df = pd.read_csv(dataset_path + 'auc.distracted.driver.test.csv')\n",
    "    x = df.iloc[:,0]\n",
    "    y = df.iloc[:,1]\n",
    "    X_valid = []\n",
    "    Y_valid = []\n",
    "    print('Read test images')\n",
    "    for i in range (0,len(x)):\n",
    "        fl = dataset_path + r'v1_cam1_no_split/' + r'/'.join(x[i].split('/')[-2:])\n",
    "        print(f\"Reading image {i}/{len(x)}\")\n",
    "        img = get_im_cv2(fl)\n",
    "        X_valid.append(img)\n",
    "        Y_valid.append(y[i])\n",
    "    return X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_data(data, path):\n",
    "    if os.path.isdir(os.path.dirname(path)):\n",
    "        file = open(path, 'wb')\n",
    "        pickle.dump(data, file)\n",
    "        file.close()\n",
    "    else:\n",
    "        print('Directory doesnt exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_data(path):\n",
    "    data = dict()\n",
    "    if os.path.isfile(path):\n",
    "        file = open(path, 'rb')\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_normalize_train_data():\n",
    "    # cache_path = os.path.join('/cache', 'train_r_' + str(224) + '_c_' + str(224) + '_t_' + str(3) + '.dat')\n",
    "    cache_path = r'../Project/Dataset/cache/train_v1.dat'\n",
    "    if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "        train_data, train_target= load_train()\n",
    "        cache_data((train_data, train_target), cache_path)\n",
    "    else:\n",
    "        print('Restore train from cache!')\n",
    "        (train_data, train_target) = restore_data(cache_path)\n",
    "    \n",
    "    print('Convert to numpy...')\n",
    "    train_data = np.array(train_data, dtype=np.uint8)\n",
    "    train_target = np.array(train_target, dtype=np.uint8)\n",
    "    \n",
    "    print('Reshape...')\n",
    "    train_data = train_data.transpose((0, 1, 2, 3))\n",
    "\n",
    "    # Normalise the train data\n",
    "    print('Convert to float...')\n",
    "    train_data = train_data.astype('float16')\n",
    "    mean_pixel = [80.857, 81.106, 82.928]\n",
    "    \n",
    "    print('Substract 0...')\n",
    "    train_data[:, :, :, 0] -= mean_pixel[0]\n",
    "    \n",
    "    print('Substract 1...')\n",
    "    train_data[:, :, :, 1] -= mean_pixel[1]\n",
    "\n",
    "    print('Substract 2...')\n",
    "    train_data[:, :, :, 2] -= mean_pixel[2]\n",
    "\n",
    "    train_target = utils.to_categorical(train_target, 10)\n",
    "    \n",
    "    # Shuffle experiment START !!\n",
    "    perm = permutation(len(train_target))\n",
    "    train_data = train_data[perm]\n",
    "    train_target = train_target[perm]\n",
    "    # Shuffle experiment END !!\n",
    "    \n",
    "    print('Train shape:', train_data.shape)\n",
    "    print(train_data.shape[0], 'train samples')\n",
    "    return train_data, train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_normalize_test_data():\n",
    "    start_time = time.time()\n",
    "    # cache_path = os.path.join('/cache', 'test_r_' + str(224) + '_c_' + str(224) + '_t_' + str(3) + '.dat')\n",
    "    cache_path = r'../Project/Dataset/cache/test_v1.dat'\n",
    "\n",
    "    if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "        test_data, test_target = load_valid()\n",
    "        cache_data((test_data, test_target ), cache_path)\n",
    "    else:\n",
    "        print('Restore test from cache [{}]!')\n",
    "        (test_data, test_target) = restore_data(cache_path)\n",
    "\n",
    "    test_data = np.array(test_data, dtype=np.uint8)\n",
    "    test_data = test_data.transpose((0, 1, 2, 3))\n",
    "\n",
    "    # Normalise the test data data\n",
    "\n",
    "    test_data = test_data.astype('float16')\n",
    "    mean_pixel = [80.857, 81.106, 82.928]\n",
    "\n",
    "    test_data[:, :, :, 0] -= mean_pixel[0]\n",
    "\n",
    "    test_data[:, :, :, 1] -= mean_pixel[1]\n",
    "\n",
    "    test_data[:, :, :, 2] -= mean_pixel[2]\n",
    "\n",
    "    test_target = utils.to_categorical(test_target, 10)\n",
    "    print('Test shape:', test_data.shape)\n",
    "    print(test_data.shape[0], 'test samples')\n",
    "    print('Read and process test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return test_data, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore train from cache!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert to numpy...\n",
      "Reshape...\n",
      "Convert to float...\n",
      "Substract 0...\n",
      "Substract 1...\n",
      "Substract 2...\n",
      "Train shape: (12977, 224, 224, 3)\n",
      "12977 train samples\n",
      "Restore test from cache [{}]!\n",
      "Test shape: (4331, 224, 224, 3)\n",
      "4331 test samples\n",
      "Read and process test data time: 3.49 seconds\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = read_and_normalize_train_data()\n",
    "X_valid, Y_valid = read_and_normalize_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_16(input_tensor=None, input_shape=None, alpha=1, shallow=False, classes=10):\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape =(224,224,3))\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    print(img_input)\n",
    "\n",
    "    # 1st Conv Block\n",
    "\n",
    "    x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(img_input)\n",
    "    x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "    \n",
    "    # 2nd Conv Block\n",
    "\n",
    "    x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "    x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "    \n",
    "    # 3rd Conv block\n",
    "\n",
    "    x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "    x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "    x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    # 4th Conv block\n",
    "\n",
    "    x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "    x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "    x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # 5th Conv block\n",
    "\n",
    "    x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "    x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "    x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "    x= Dropout(0.3)(x)\n",
    "\n",
    "    # th Conv block\n",
    "\n",
    "    x = Conv2D (filters =512, kernel_size =7, padding ='same', activation='relu')(x)\n",
    "    x= Dropout(0.4)(x)\n",
    "    x = Conv2D (filters =512, kernel_size =1, padding ='same', activation='relu')(x)\n",
    "    x= Dropout(0.5)(x)\n",
    "    x = Conv2D (filters =10, kernel_size =1, padding ='same', activation='softmax')(x)\n",
    "    # output = Dense(10, activation='softmax')(x)\n",
    "    output = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # creating the model\n",
    "\n",
    "    model = Model (inputs=img_input, outputs =output)\n",
    "    model.summary()    \n",
    "\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    model = Model(inputs, output, name='VGG_16')\n",
    "    # model.load_weights('weights.h5')\n",
    "    adam = SGD(learning_rate=0.0001, momentum=0.9, weight_decay=10e-6)\n",
    "\n",
    "    model.compile(adam, loss=CategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\")\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 112, 112, 64)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 56, 56, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 28, 28, 256)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 14, 14, 512)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 7, 7, 512)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 7, 7, 512)         12845568  \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 7, 7, 512)         262656    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 7, 7, 10)          5130      \n",
      "                                                                 \n",
      " global_average_pooling2d_2  (None, 10)                0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27828042 (106.16 MB)\n",
      "Trainable params: 27828042 (106.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG_16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            shear_range=0.2\n",
    "            )\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12977, 224, 224, 3)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 20:11:43.774242: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inVGG_16/dropout_10/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-03-07 20:11:44.095690: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-03-07 20:11:44.095730: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 6348288093820418842\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node categorical_crossentropy/Log defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_1893582/2491744665.py\", line 5, in <module>\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/backend.py\", line 5592, in categorical_crossentropy\n\nJIT compilation failed.\n\t [[{{node categorical_crossentropy/Log}}]] [Op:__inference_train_function_6425]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [ModelCheckpoint(weights_path, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 5\u001b[0m hist\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node categorical_crossentropy/Log defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_1893582/2491744665.py\", line 5, in <module>\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/backend.py\", line 5592, in categorical_crossentropy\n\nJIT compilation failed.\n\t [[{{node categorical_crossentropy/Log}}]] [Op:__inference_train_function_6425]"
     ]
    }
   ],
   "source": [
    "weights_path=r'./Checkpoint/'       \n",
    "callbacks = [ModelCheckpoint(weights_path, monitor='val_acc', save_best_only=True, verbose=1)]\n",
    "\n",
    "print(X_train.shape)\n",
    "hist=model.fit(datagen.flow(X_train, Y_train, batch_size=batch_size), epochs=nb_epoch, verbose=1, validation_data=(X_valid, Y_valid), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hist.history).to_csv(r'../Project/Dataset/cache/try_hist.csv')\n",
    "\n",
    "predictions_valid = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=1)\n",
    "cm1=confusion_matrix(Y_valid.argmax(axis=1), predictions_valid.argmax(axis=1))\n",
    "ss=cm1[0,0]+cm1[1,1]+cm1[2,2]+cm1[3,3]+cm1[4,4]+cm1[5,5]+cm1[6,6]+cm1[7,7]+cm1[8,8]+cm1[9,9];\n",
    "test_accuracy=np.divide(ss,4331);\n",
    "print('Test Accuracy:',test_accuracy)\n",
    "\n",
    "ppath=os.path.join('/home/gpu3/Desktop/mobileVGG','cache','confusion_mat.npy')\n",
    "np.save(ppath, cm1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
