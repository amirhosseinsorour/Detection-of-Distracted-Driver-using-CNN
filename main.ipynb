{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "import cv2\n",
    "from numpy.random import permutation\n",
    "from keras.utils import np_utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cache = 1\n",
    "dataset_path = r'../Distracted-Driver-Detection/Dataset/'\n",
    "np.random.seed(2016)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(src=img, dsize=(224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    df = pd.read_csv(dataset_path + 'auc.distracted.driver.train.csv')\n",
    "    x = df.iloc[:,0]\n",
    "    y = df.iloc[:,1]\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    print('Read train images')\n",
    "    for i in range (0,len(x)):\n",
    "        fl= dataset_path + r'v1_cam1_no_split/' + r'/'.join(x[i].split('/')[-2:])\n",
    "        print(fl)\n",
    "        img = get_im_cv2(fl)\n",
    "        X_train.append(img)\n",
    "        Y_train.append(y[i])\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_valid():\n",
    "    df = pd.read_csv(dataset_path + 'auc.distracted.driver.test.csv')\n",
    "    x = df.iloc[:,0]\n",
    "    y = df.iloc[:,1]\n",
    "    X_valid = []\n",
    "    Y_valid = []\n",
    "    print('Read test images')\n",
    "    for i in range (0,len(x)):\n",
    "        fl = dataset_path + r'v1_cam1_no_split/' + r'/'.join(x[i].split('/')[-2:])\n",
    "        print(fl)\n",
    "        img = get_im_cv2(fl)\n",
    "        X_valid.append(img)\n",
    "        Y_valid.append(y[i])\n",
    "    return X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_data(data, path):\n",
    "    if os.path.isdir(os.path.dirname(path)):\n",
    "        file = open(path, 'wb')\n",
    "        pickle.dump(data, file)\n",
    "        file.close()\n",
    "    else:\n",
    "        print('Directory doesnt exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_data(path):\n",
    "    data = dict()\n",
    "    if os.path.isfile(path):\n",
    "        file = open(path, 'rb')\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_normalize_train_data():\n",
    "    cache_path = os.path.join('/home/gpu3/Desktop/mobileVGG','cache', 'train_r_' + str(224) + '_c_' + str(224) + '_t_' + str(3) + '.dat')\n",
    "    if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "        train_data, train_target= load_train()\n",
    "        cache_data((train_data, train_target), cache_path)\n",
    "    else:\n",
    "        print('Restore train from cache!')\n",
    "        (train_data, train_target) = restore_data(cache_path)\n",
    "    \n",
    "    print('Convert to numpy...')\n",
    "    train_data = np.array(train_data, dtype=np.uint8)\n",
    "    train_target = np.array(train_target, dtype=np.uint8)\n",
    "    \n",
    "    print('Reshape...')\n",
    "    train_data = train_data.transpose((0, 1, 2, 3))\n",
    "\n",
    "    # Normalise the train data\n",
    "    print('Convert to float...')\n",
    "    train_data = train_data.astype('float16')\n",
    "    mean_pixel = [80.857, 81.106, 82.928]\n",
    "    \n",
    "    print('Substract 0...')\n",
    "    train_data[:, :, :, 0] -= mean_pixel[0]\n",
    "    \n",
    "    print('Substract 1...')\n",
    "    train_data[:, :, :, 1] -= mean_pixel[1]\n",
    "\n",
    "    print('Substract 2...')\n",
    "    train_data[:, :, :, 2] -= mean_pixel[2]\n",
    "\n",
    "    train_target = np_utils.to_categorical(train_target, 10)\n",
    "    \n",
    "    # Shuffle experiment START !!\n",
    "    perm = permutation(len(train_target))\n",
    "    train_data = train_data[perm]\n",
    "    train_target = train_target[perm]\n",
    "    # Shuffle experiment END !!\n",
    "    \n",
    "    print('Train shape:', train_data.shape)\n",
    "    print(train_data.shape[0], 'train samples')\n",
    "    return train_data, train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_normalize_test_data():\n",
    "    start_time = time.time()\n",
    "    cache_path = os.path.join('/home/gpu3/Desktop/mobileVGG','cache', 'test_r_' + str(224) + '_c_' + str(224) + '_t_' + str(3) + '.dat')\n",
    "\n",
    "    if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "        test_data, test_target = load_valid()\n",
    "        cache_data((test_data, test_target ), cache_path)\n",
    "    else:\n",
    "        print('Restore test from cache [{}]!')\n",
    "        (test_data, test_target) = restore_data(cache_path)\n",
    "\n",
    "    test_data = np.array(test_data, dtype=np.uint8)\n",
    "    test_data = test_data.transpose((0, 1, 2, 3))\n",
    "\n",
    "    # Normalise the test data data\n",
    "\n",
    "    test_data = test_data.astype('float16')\n",
    "    mean_pixel = [80.857, 81.106, 82.928]\n",
    "\n",
    "    test_data[:, :, :, 0] -= mean_pixel[0]\n",
    "\n",
    "    test_data[:, :, :, 1] -= mean_pixel[1]\n",
    "\n",
    "    test_data[:, :, :, 2] -= mean_pixel[2]\n",
    "\n",
    "    test_target = np_utils.to_categorical(test_target, 10)\n",
    "    print('Test shape:', test_data.shape)\n",
    "    print(test_data.shape[0], 'test samples')\n",
    "    print('Read and process test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return test_data, test_target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
